{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TS35SlLHIyLa"
   },
   "outputs": [],
   "source": [
    "#Importando bibliotecas\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yICbZk8TI1W0"
   },
   "outputs": [],
   "source": [
    "#Rede neural\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inCh, outCh, stride):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inCh, out_channels=outCh,\n",
    "                            kernel_size=3, padding=1, stride=stride),\n",
    "            nn.BatchNorm2d(outCh),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=outCh, out_channels=outCh,\n",
    "                            kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(outCh)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inCh != outCh:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inCh, out_channels=outCh,\n",
    "                            kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outCh)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer_1 = self.make_layer(ResidualBlock, 64, 64, stride=1)\n",
    "        self.layer_2 = self.make_layer(ResidualBlock, 64, 128, stride=2)\n",
    "        self.layer_3 = self.make_layer(ResidualBlock, 128, 256, stride=2)\n",
    "        self.layer_4 = self.make_layer(ResidualBlock, 256, 512, stride=2)\n",
    "        self.avgpool = nn.AvgPool2d((3, 3), stride=2)\n",
    "        self.fc = nn.Linear(512 * 1 * 1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 512*1*1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def make_layer(self, block, inCh, outCh, stride, block_num=2):\n",
    "        layers = []\n",
    "        layers.append(block(inCh, outCh, stride))\n",
    "        for i in range(block_num - 1):\n",
    "            layers.append(block(outCh, outCh, 1))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LyWl62p5I5GC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro.zanineli/anaconda3/envs/ilumpy/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#Parâmetros básicos\n",
    "\n",
    "batchsize=128\n",
    "worker=2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "transform_norm = transforms.Normalize(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "b98TK7VvJ7b_"
   },
   "outputs": [],
   "source": [
    "#Ataques\n",
    "\n",
    "def fgsm(model, X, y, epsilon=8.0/255.0):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    loss = nn.CrossEntropyLoss()(model(transform_norm(X + delta)), y)\n",
    "    loss.backward()\n",
    "    return epsilon * delta.grad.detach().sign()\n",
    "\n",
    "def pgd_linf(model, X, y, epsilon=8.0/255.0, alpha=2/255, num_iter=7, randomize=False):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    if randomize:\n",
    "        delta = torch.rand_like(X, requires_grad=True)\n",
    "        delta.data = delta.data * 2 * epsilon - epsilon\n",
    "    else:\n",
    "        delta = torch.zeros_like(X, requires_grad=True)\n",
    "\n",
    "    for t in range(num_iter):\n",
    "        loss = nn.CrossEntropyLoss()(model(transform_norm(X + delta)), y)\n",
    "        loss.backward()\n",
    "        delta.data = (delta + alpha * delta.grad.detach().sign()).clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "    return delta.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W0EGyDMtKDTG"
   },
   "outputs": [],
   "source": [
    "#Treinamento adversário\n",
    "\n",
    "def epoch_adversarial_train_ds(loader, model, attack,  P_up, minibatchsize, opt=None, **kwargs):\n",
    "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
    "    total_loss, total_err, total_acc = 0., 0., 0.\n",
    "    set_selected=[]\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        yy = torch.cat((y, y), dim=0)\n",
    "        delta = attack(model, X, y, **kwargs)\n",
    "        adv = transform_norm(X + delta)\n",
    "        yp_adv = model(adv)\n",
    "        loss_adv = nn.CrossEntropyLoss()(yp_adv, y)\n",
    "        clean = transform_norm(X)\n",
    "        yp_clean = model(clean)\n",
    "        loss_clean = nn.CrossEntropyLoss()(yp_clean, y)\n",
    "\n",
    "        yp = torch.cat((yp_adv,yp_clean), dim=0)\n",
    "        image =  torch.cat((adv, clean), dim=0)\n",
    "\n",
    "        myloss = compute_crossentropyloss_manual(yp,yy)\n",
    "        total_acc += (yp.max(dim=1)[1] == yy).sum().item()/len(myloss)\n",
    "        size_sel = int(P_up *2* minibatchsize)\n",
    "\n",
    "        error_signal = np.argsort(myloss)\n",
    "        error_signal = error_signal[::-1]\n",
    "        selec = error_signal[0:size_sel]\n",
    "\n",
    "        set_selected.append(selec)\n",
    "        label_aux = yy.cpu().detach().numpy()\n",
    "        yy = torch.from_numpy(label_aux[selec])\n",
    "        image_aux = image.cpu().detach().numpy()\n",
    "        image = torch.from_numpy(image_aux[selec])\n",
    "\n",
    "        yp = model(image.cpu())\n",
    "        loss = nn.CrossEntropyLoss()(yp.cpu(), yy.cpu())\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        total_err += (yp.cpu().max(dim=1)[1] == yy.cpu()).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "\n",
    "    return 0., total_loss / len(loader.dataset), total_err / (2*P_up*len(loader.dataset))\n",
    "\n",
    "def compute_crossentropyloss_manual(x,y0):\n",
    "    \"\"\"\n",
    "    x is the vector of probabilities with shape (batch_size,C)\n",
    "    y0 shape is the same (batch_size), whose entries are integers from 0 to C-1\n",
    "    \"\"\"\n",
    "    myloss=[]\n",
    "    loss = 0.\n",
    "    n_batch, n_class = x.shape\n",
    "    # print(n_class)\n",
    "    for x1,y1 in zip(x,y0):\n",
    "        x1 = x1.cpu().detach().numpy().astype(np.float128)\n",
    "        class_index = int(y1.item())\n",
    "        loss = -np.log(np.exp(x1[class_index])/(np.exp(x1).sum()))\n",
    "        myloss.append(loss)\n",
    "    loss = - loss/n_batch\n",
    "\n",
    "    return myloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7L9E1-aqKOe4"
   },
   "outputs": [],
   "source": [
    "#Testes\n",
    "\n",
    "def epoch(loader, model, opt=None):\n",
    "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "    total_loss, total_err = 0., 0.\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = transform_norm(X)\n",
    "        yp = model(X)\n",
    "        loss = nn.CrossEntropyLoss()(yp, y)\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        total_err += (yp.max(dim=1)[1] == y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def epoch_adversarial(loader, model, attack, opt=None, **kwargs):\n",
    "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
    "    total_loss, total_err = 0., 0.\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # with adversarial example\n",
    "        delta = attack(model, X, y, **kwargs)\n",
    "        adv = transform_norm(X + delta)\n",
    "        yp = model(adv)\n",
    "        loss = nn.CrossEntropyLoss()(yp, y)\n",
    "        if opt:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total_err += (yp.max(dim=1)[1] == y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B91o6yLRKUye"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Importando dataset\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomCrop(32, padding=4),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor()])\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=worker)\n",
    "test_loader = DataLoader(testset, batch_size=batchsize, shuffle=False, num_workers=worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pa-vc61xK6HH"
   },
   "outputs": [],
   "source": [
    "#Seleção de dados\n",
    "\n",
    "P_up = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFQQSkWKK-1k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train Error: 0.0; Test Acc: 0.1; Adversarial Acc: 0.1\n",
      "Train Loss: 2.4485930293273928; Test Loss: 2.301503427886963; Adversarial Loss: 2.3031305778503417\n"
     ]
    }
   ],
   "source": [
    "for P_up in [.2,.4,.6,.8,1]:\n",
    "    \n",
    "    #Looping de treinamento\n",
    "\n",
    "    model_cnn_robust = ResNet18().to(device)\n",
    "    \n",
    "    LR = 0.1\n",
    "\n",
    "    opt = optim.SGD(model_cnn_robust.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "    train_err_all=[]\n",
    "    test_err_all = []\n",
    "    adv_err_all = []\n",
    "    all_set_selected=[]\n",
    "    time_train=[]\n",
    "    P_up_all=[]\n",
    "\n",
    "    ini = time.time()\n",
    "\n",
    "    for t in range(200):\n",
    "        \n",
    "        if t == 99 or t == 149:\n",
    "            opt = optim.SGD(model_cnn_robust.parameters(), lr=LR, momentum=0.9, weight_decay=0.1)\n",
    "        else:\n",
    "            opt = optim.SGD(model_cnn_robust.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "        \n",
    "        train_err, train_loss, acc = epoch_adversarial_train_ds(train_loader, model_cnn_robust, pgd_linf, P_up, batchsize, opt)\n",
    "        P_up_all.append(P_up)\n",
    "        #P_up = (1-acc)*P_up\n",
    "        test_err, test_loss = epoch(test_loader, model_cnn_robust)\n",
    "\n",
    "        adv_err, adv_loss = epoch_adversarial(test_loader, model_cnn_robust, pgd_linf)\n",
    "        train_err_all.append(train_err)\n",
    "        test_err_all.append(test_err)\n",
    "        adv_err_all.append(adv_err)\n",
    "\n",
    "        print('\\n')\n",
    "        print(f'Train Error: {train_err}; Test Acc: {test_err}; Adversarial Acc: {adv_err}')\n",
    "        print(f'Train Loss: {train_loss}; Test Loss: {test_loss}; Adversarial Loss: {adv_loss}')\n",
    "        with open('adv_train_pup_1.pickle', 'wb') as f:\n",
    "            pickle.dump([train_err_all, test_err_all, adv_err_all], f)\n",
    "    torch.save(model_cnn_robust.state_dict(), f\"model_adv_train_pup_DS={P_up}_LR={LR}.pt\")\n",
    "\n",
    "    fim = time.time()\n",
    "    print(f'Tempo de execução: {fim-ini}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
